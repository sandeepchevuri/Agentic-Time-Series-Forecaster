{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b1e63a",
   "metadata": {},
   "source": [
    "# Using TimeCopilot with AWS Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e50249",
   "metadata": {},
   "source": [
    "## Requirements \n",
    "\n",
    "1. An AWS account\n",
    "2. Access to Bedrock in that account \n",
    "    - Through a AWS Bedrock API key\n",
    "    - Through a standard AWS access key set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96f47c9",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from timecopilot import TimeCopilot\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66c0af",
   "metadata": {},
   "source": [
    "## Environment Variables\n",
    "\n",
    "Api keys and other configuration elements may need to be loaded into the environment so pydantic can read them during setup, at least when specifying the llm with a string. \n",
    "\n",
    "If using a Bedrock API key, `AWS_DEFAULT_REGION` needs to be set to your preferred region. You'll also need to set either `AWS_BEARER_TOKEN` if using a bedrock api key or `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` if using a standard AWS access key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fc29f",
   "metadata": {},
   "source": [
    "This is how you would load the environment variables in in a Unix-like system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e55fe6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export AWS_DEFAULT_REGION='us-east-1'  # or your preferred region\n",
    "# and one of the following:\n",
    "export AWS_BEARER_TOKEN_BEDROCK='your-api-key'\n",
    "# or:\n",
    "export AWS_ACCESS_KEY_ID='your-access-key'\n",
    "export AWS_SECRET_ACCESS_KEY='your-secret-key'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c7220",
   "metadata": {},
   "source": [
    "If you store your environment variablesles in a `.env` file, you can use the following load them into your environment from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb8c2a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export $(grep -v '^#' .env | xargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10407c4f",
   "metadata": {},
   "source": [
    "Or you could load it in python with [dotenv](https://pypi.org/project/python-dotenv/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7954a291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6758b27",
   "metadata": {},
   "source": [
    "## TimeCopilot Agent\n",
    "\n",
    "TimeCopilot uses Pydantic to work with llms, so you specify the LLM the same way you'd specify an Agent with Pydantic. Either with a string in the form `'bedrock:model-id'` or instantiating a model with `pydantic_ai.models.bedrock.BedrockConverseModel`. When using Bedrock, models are specified with a Model ID which you can find by going to a model in Bedrock's model catalog and looking at the Model ID field for that model.\n",
    "\n",
    "For more details on how Pydantic works with Bedrock, see the [Pydantic docs on bedrock](https://ai.pydantic.dev/models/bedrock/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8b0d6",
   "metadata": {},
   "source": [
    "### String example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667ef66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TimeCopilot(\n",
    "    llm='bedrock:us.anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd658a8",
   "metadata": {},
   "source": [
    "### BedrockConverseModel example:\n",
    "\n",
    "If you want to load your keys with a non-environment based method, this is where you would use those keys by [instantiating BedrockConverseModel with a BedrockProvider](https://ai.pydantic.dev/models/bedrock/#provider-argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29415044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.bedrock import BedrockConverseModel\n",
    "\n",
    "model = BedrockConverseModel(\n",
    "    'us.anthropic.claude-3-5-sonnet-20241022-v2:0'\n",
    "    \n",
    ")\n",
    "tc = TimeCopilot(\n",
    "    llm=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99789d7b",
   "metadata": {},
   "source": [
    "## Use your TimeCopilot agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2c146",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2332b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://timecopilot.s3.amazonaws.com/public/data/air_passengers.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425289c",
   "metadata": {},
   "source": [
    "### Generate Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6b035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 122.86it/s]\n",
      "1it [00:00, 21.17it/s]\n",
      "1it [00:00,  8.47it/s]\n",
      "0it [00:00, ?it/s]11:33:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:33:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "1it [00:03,  3.61s/it]\n",
      "1it [00:00, 152.35it/s]\n",
      "11:34:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "0it [00:00, ?it/s]11:34:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "1it [00:03,  3.05s/it]11:34:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2it [00:06,  3.04s/it]11:34:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "3it [00:09,  3.10s/it]11:34:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "4it [00:12,  3.12s/it]11:34:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "5it [00:15,  3.14s/it]11:34:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "6it [00:18,  3.14s/it]11:34:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "7it [00:22,  3.21s/it]11:34:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "8it [00:25,  3.21s/it]11:34:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "9it [00:28,  3.16s/it]11:34:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10it [00:31,  3.18s/it]11:34:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:34:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11it [00:34,  3.16s/it]\n"
     ]
    }
   ],
   "source": [
    "result = tc.forecast(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce7569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentRunResult(output=ForecastAgentOutput(tsfeatures_analysis='The time series analysis reveals strong seasonal and trend components:\\n1. High seasonal strength (0.98) indicates pronounced yearly patterns\\n2. Strong positive autocorrelation (x_acf1: 0.95) suggests strong trend\\n3. Significant Holt-Winters seasonality (hw_gamma: 0.75) confirms seasonal importance\\n4. High stability (0.93) indicates consistent patterns\\n5. Non-stationary series (KPSS: 2.74) confirms strong trend\\n6. Clear seasonal peaks (July) and troughs (November)', selected_model='Prophet', model_details='Prophet is a decomposition-based forecasting model developed by Facebook that:\\n1. Handles multiple seasonalities automatically\\n2. Is robust to missing data and outliers\\n3. Automatically detects trend changes\\n4. Incorporates holiday effects\\n5. Works well with strong seasonal patterns and trends\\n6. Uses Bayesian methods for uncertainty estimation', model_comparison='Cross-validation results (MASE):\\n1. Prophet: 1.09 (best performer)\\n2. DynamicOptimizedTheta: 1.66\\n3. AutoETS: 2.38\\n4. AutoARIMA: 2.40\\n5. SeasonalNaive: 2.49\\n\\nProphet significantly outperformed other models, showing superior handling of the strong seasonal patterns and trend. The DynamicOptimizedTheta performed second-best but with notably higher error. Traditional models (AutoETS, AutoARIMA) struggled with the combination of strong trend and seasonality.', is_better_than_seasonal_naive=True, reason_for_selection='Prophet was selected because:\\n1. Best MASE score (1.09) among all tested models\\n2. Significantly outperformed the seasonal naive benchmark (2.49)\\n3. Well-suited for the identified strong seasonal patterns\\n4. Capable of handling the pronounced trend component\\n5. Robust to the detected anomalies\\n6. Provides good uncertainty estimates', forecast_analysis='The forecast shows:\\n1. Continuing upward trend in passenger numbers\\n2. Preserved seasonal pattern with peaks in summer months\\n3. Clear seasonal amplitude that increases with the trend\\n4. Forecast maintains realistic growth rate based on historical patterns\\n5. Summer peaks (July-August) consistently show highest passenger numbers\\n6. Winter troughs (November-January) show expected seasonal dips\\n7. Growth trajectory appears sustainable and aligned with historical patterns', anomaly_analysis='Anomaly analysis reveals:\\n1. 8 anomalies detected (6.1% of data points)\\n2. Concentrated in summer months (July-August)\\n3. Most anomalies in later years (1955-1960)\\n4. Suggests unusual peak season activity\\n5. Pattern indicates systematic summer overperformance\\n6. Anomalies align with rapid growth periods\\n7. No anomalies in winter months, indicating stable low-season patterns\\n8. Recommendations:\\n   - Monitor summer capacity planning\\n   - Consider these peaks for future forecasting\\n   - Adjust resources for high-season operations', user_query_response='The analysis has been completed following all required steps:\\n\\n1. Time series features show strong seasonality and trend\\n2. Prophet model selected as best performer with MASE of 1.09\\n3. Forecast indicates continued growth with seasonal patterns\\n4. 8 anomalies detected, mainly in summer peaks\\n\\nThe time series represents monthly air passenger counts, showing clear yearly patterns with summer peaks and winter troughs. The forecast suggests continued growth while maintaining these seasonal patterns. Special attention should be paid to summer months due to detected anomalies in peak seasons.'))\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3008720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time series analysis reveals strong seasonal and trend components:\n",
      "1. High seasonal strength (0.98) indicates pronounced yearly patterns\n",
      "2. Strong positive autocorrelation (x_acf1: 0.95) suggests strong trend\n",
      "3. Significant Holt-Winters seasonality (hw_gamma: 0.75) confirms seasonal importance\n",
      "4. High stability (0.93) indicates consistent patterns\n",
      "5. Non-stationary series (KPSS: 2.74) confirms strong trend\n",
      "6. Clear seasonal peaks (July) and troughs (November)\n"
     ]
    }
   ],
   "source": [
    "print(result.output.tsfeatures_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe2ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time series analysis reveals strong seasonal and trend components:\n",
      "1. High seasonal strength (0.98) indicates pronounced yearly patterns\n",
      "2. Strong positive autocorrelation (x_acf1: 0.95) suggests strong trend\n",
      "3. Significant Holt-Winters seasonality (hw_gamma: 0.75) confirms seasonal importance\n",
      "4. High stability (0.93) indicates consistent patterns\n",
      "5. Non-stationary series (KPSS: 2.74) confirms strong trend\n",
      "6. Clear seasonal peaks (July) and troughs (November)\n"
     ]
    }
   ],
   "source": [
    "print(result.output.tsfeatures_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b660c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        unique_id         ds     Prophet\n",
      "0   AirPassengers 1961-01-01  466.560401\n",
      "1   AirPassengers 1961-02-01  461.042082\n",
      "2   AirPassengers 1961-03-01  493.413542\n",
      "3   AirPassengers 1961-04-01  492.113653\n",
      "4   AirPassengers 1961-05-01  496.445709\n",
      "5   AirPassengers 1961-06-01  537.592041\n",
      "6   AirPassengers 1961-07-01  577.166093\n",
      "7   AirPassengers 1961-08-01  577.599117\n",
      "8   AirPassengers 1961-09-01  529.038266\n",
      "9   AirPassengers 1961-10-01  493.889181\n",
      "10  AirPassengers 1961-11-01  460.030234\n",
      "11  AirPassengers 1961-12-01  489.392785\n",
      "12  AirPassengers 1962-01-01  502.415939\n",
      "13  AirPassengers 1962-02-01  496.321423\n",
      "14  AirPassengers 1962-03-01  531.969966\n",
      "15  AirPassengers 1962-04-01  528.065107\n",
      "16  AirPassengers 1962-05-01  534.174659\n",
      "17  AirPassengers 1962-06-01  573.615281\n",
      "18  AirPassengers 1962-07-01  614.245102\n",
      "19  AirPassengers 1962-08-01  614.206790\n",
      "20  AirPassengers 1962-09-01  566.306418\n",
      "21  AirPassengers 1962-10-01  530.606803\n",
      "22  AirPassengers 1962-11-01  497.766797\n",
      "23  AirPassengers 1962-12-01  527.289739\n"
     ]
    }
   ],
   "source": [
    "print(result.fcst_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f098965",
   "metadata": {},
   "source": [
    "### Make Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af53310",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = tc.query(\"What will the total number of passengers be in the next year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ebf6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me help you calculate the total number of passengers predicted by the Prophet model (our best performing model with MASE = 1.09) for the forecast period.\n",
      "\n",
      "Looking at the forecast data in fcst_df, I'll sum up all the predicted values:\n",
      "\n",
      "From the \"AirPassengers\" forecasts, let me sum up the Prophet predictions:\n",
      "466.56 + 461.04 + 493.41 + 492.11 + 496.45 + 537.59 + 577.17 + 577.60 + 529.04 + 493.89 + 460.03 + 489.39 + 502.42 + 496.32 + 531.97 + 528.07 + 534.17 + 573.62 + 614.25 + 614.21 + 566.31 + 530.61 + 497.77 + 527.29\n",
      "\n",
      "The total predicted number of passengers for the next 24 months is approximately 12,591 thousand passengers.\n",
      "\n",
      "Breaking this down:\n",
      "- First 12 months total: 6,074 thousand passengers\n",
      "- Second 12 months total: 6,517 thousand passengers\n",
      "\n",
      "You can notice an increasing trend in the passenger numbers from year to year, which is consistent with the strong trend feature (trend = 0.997) we see in our features data. The predictions also maintain the seasonal pattern with higher numbers during summer months (peaks around July-August) and lower numbers during winter months (troughs around November-December).\n",
      "\n",
      "Let me show you the forecast visualization so you can see this pattern:\n"
     ]
    }
   ],
   "source": [
    "print(query_result.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timecopilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
